{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347de406",
   "metadata": {},
   "source": [
    "# fuzzymatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9525a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzymatcher\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f17dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 578907 entries, 0 to 578906\n",
      "Data columns (total 25 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id_1          578907 non-null  object \n",
      " 1   name_1        578907 non-null  object \n",
      " 2   latitude_1    578907 non-null  float64\n",
      " 3   longitude_1   578907 non-null  float64\n",
      " 4   address_1     475383 non-null  object \n",
      " 5   city_1        512928 non-null  object \n",
      " 6   state_1       452316 non-null  object \n",
      " 7   zip_1         359509 non-null  object \n",
      " 8   country_1     578899 non-null  object \n",
      " 9   url_1         231806 non-null  object \n",
      " 10  phone_1       270022 non-null  object \n",
      " 11  categories_1  562613 non-null  object \n",
      " 12  id_2          578907 non-null  object \n",
      " 13  name_2        578907 non-null  object \n",
      " 14  latitude_2    578907 non-null  float64\n",
      " 15  longitude_2   578907 non-null  float64\n",
      " 16  address_2     312497 non-null  object \n",
      " 17  city_2        367490 non-null  object \n",
      " 18  state_2       309689 non-null  object \n",
      " 19  zip_2         224827 non-null  object \n",
      " 20  country_2     578901 non-null  object \n",
      " 21  url_2         84850 non-null   object \n",
      " 22  phone_2       118963 non-null  object \n",
      " 23  categories_2  502931 non-null  object \n",
      " 24  match         578907 non-null  bool   \n",
      "dtypes: bool(1), float64(4), object(20)\n",
      "memory usage: 106.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1138812 entries, 0 to 1138811\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   id                 1138812 non-null  object \n",
      " 1   name               1138811 non-null  object \n",
      " 2   latitude           1138812 non-null  float64\n",
      " 3   longitude          1138812 non-null  float64\n",
      " 4   address            742191 non-null   object \n",
      " 5   city               839623 non-null   object \n",
      " 6   state              718226 non-null   object \n",
      " 7   zip                543386 non-null   object \n",
      " 8   country            1138801 non-null  object \n",
      " 9   url                267724 non-null   object \n",
      " 10  phone              342855 non-null   object \n",
      " 11  categories         1040505 non-null  object \n",
      " 12  point_of_interest  1138812 non-null  object \n",
      "dtypes: float64(2), object(11)\n",
      "memory usage: 112.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#data import\n",
    "\n",
    "pairs = pd.read_csv('/Users/maxhdarby/Dropbox/foursquare_location_matching_data/pairs.csv',index_col = False)\n",
    "s_s = pd.read_csv('/Users/maxhdarby/Dropbox/foursquare_location_matching_data/sample_submission.csv',index_col = False)\n",
    "test = pd.read_csv('/Users/maxhdarby/Dropbox/foursquare_location_matching_data/test.csv',index_col = False)\n",
    "train = pd.read_csv('/Users/maxhdarby/Dropbox/foursquare_location_matching_data/train.csv',index_col = False)\n",
    "\n",
    "#print(pairs.head())\n",
    "print(pairs.info())\n",
    "print(train.info())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1884f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some useful formatting \n",
    "#.str.normalize('NFKD')\n",
    "#.drop_duplicates(subset=['column_name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d1d2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample dataset for testing\n",
    "sub_df = train.head(10)\n",
    "full_df = train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe2f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           __id_left        __id_right  match_score  match_rank  \\\n",
      "0   E_000001272c6c5d  E_000001272c6c5d     0.473550           1   \n",
      "1   E_000002eae2a589  E_000002eae2a589     0.326303           1   \n",
      "2   E_000007f24ebc95  E_000007f24ebc95     0.237095           1   \n",
      "3   E_000008a8ba4f48  E_000008a8ba4f48     0.163151           1   \n",
      "4   E_00001d92066153  E_00001d92066153     0.463515           1   \n",
      "5   E_000023d8f4be44  E_000023d8f4be44     0.326303           1   \n",
      "6   E_00002a131a2bf6  E_00002a131a2bf6     0.479419           1   \n",
      "7   E_00002a131a2bf6  E_00002a131a2bf6     0.479419           1   \n",
      "8   E_00002a131a2bf6  E_00002a131a2bf6     0.479419           1   \n",
      "9   E_00002a131a2bf6  E_00002a131a2bf6     0.479419           1   \n",
      "10  E_0000764d65557e  E_0000764d65557e     0.279705           1   \n",
      "11  E_00007dcd2bb53f  E_00007dcd2bb53f     0.513596           1   \n",
      "\n",
      "                  name_left               name_right  \n",
      "0      Café Stad Oudenaarde     Café Stad Oudenaarde  \n",
      "1            Carioca Manero           Carioca Manero  \n",
      "2          ร้านตัดผมการาเกด         ร้านตัดผมการาเกด  \n",
      "3                  Turkcell                 Turkcell  \n",
      "4   Restaurante Casa Cofiño  Restaurante Casa Cofiño  \n",
      "5                Island Spa               Island Spa  \n",
      "6         ministry of youth        ministry of youth  \n",
      "7         ministry of youth        minietry of yourh  \n",
      "8         minietry of yourh        ministry of youth  \n",
      "9         minietry of yourh        minietry of yourh  \n",
      "10               McDonald's               McDonald's  \n",
      "11        TOGO'S Sandwiches        TOGO'S Sandwiches  \n"
     ]
    }
   ],
   "source": [
    "#matching process with fuzzymatcher\n",
    "#issue with fuzzymatcher is that it only joins one - \n",
    "#so how best to manage that? without re-running it multiple times?\n",
    "# use 'link_table' instead of the fuzzy_left_join\n",
    "# can set threshold using match_score > chosen_threshold\n",
    "\n",
    "# Columns to match on from df_left\n",
    "left_on = [\"name\"]\n",
    "\n",
    "# Columns to match on from df_right\n",
    "right_on = [\"name\"]\n",
    "\n",
    "# Note that if left_id_col or right_id_col are admitted a unique id will be autogenerated\n",
    "output = fuzzymatcher.link_table(sub_df, full_df, left_on, right_on, left_id_col = \"id\", right_id_col = \"id\")\n",
    "\n",
    "print(output)\n",
    "\n",
    "\n",
    "#output = fuzzymatcher.fuzzy_left_join(sub_df, full_df, left_on=\"column_name\",right_on = \"column_name\")\n",
    "\n",
    "#output.to_excel(\"output_v1.0.xlsx\")\n",
    "\n",
    "#print(\"matches complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07ba3949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "100\n",
      "88\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "#fuzzymatching with fuzzywuzzy\n",
    "print(fuzz.ratio(\"Max H Darby\",\"Darby\"))\n",
    "#Levehshtein ratio is calculated by dividing the Levenshtein distance by the maximum of the length of the string1 and string 2.\n",
    "\n",
    "print(fuzz.partial_ratio(\"Max H Darby\",\"Darby\"))\n",
    "#The output of the code gives 100 as partial_ratio() just checks if either string is a substring of the other\n",
    "\n",
    "print(fuzz.ratio(\"ร้านตัดผมการาเกด\",\" ร้านตัดผม กราาเกด\"))\n",
    "\n",
    "print(fuzz.partial_ratio(\"ร้านตัดผมการาเกด\",\" ร้านตัดผมการาเกด\"))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b340a041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print(pairs.loc[i,'city_1'],pairs.loc[i,'city_2'])\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m pairs\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m fuzz\u001b[38;5;241m.\u001b[39mratio(pairs\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_1\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     14\u001b[0m pairs\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m fuzz\u001b[38;5;241m.\u001b[39mratio(pairs\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity_1\u001b[39m\u001b[38;5;124m'\u001b[39m],pairs\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity_2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m pairs\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m fuzz\u001b[38;5;241m.\u001b[39mratio(pairs\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_1\u001b[39m\u001b[38;5;124m'\u001b[39m],pairs\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:955\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 955\u001b[0m     \u001b[43mcheck_deprecated_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[1;32m    957\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m is_iterator(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:2486\u001b[0m, in \u001b[0;36mcheck_deprecated_indexers\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_deprecated_indexers\u001b[39m(key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2482\u001b[0m     \u001b[38;5;124;03m\"\"\"Checks if the key is a deprecated indexer.\"\"\"\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mset\u001b[39m)\n\u001b[1;32m   2485\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m-> 2486\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mset\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   2487\u001b[0m     ):\n\u001b[1;32m   2488\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2489\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a set as an indexer is deprecated and will raise in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2490\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma future version. Use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2491\u001b[0m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   2492\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   2493\u001b[0m         )\n\u001b[1;32m   2494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2495\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2496\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   2497\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   2498\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#using fuzzy wuzzy to take one input and go through an dataframe - saves match scores to dataframe\n",
    "#stop forgetting that the dataframe is already matched\n",
    "pairs = pairs.fillna('')\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "#len(pairs)\n",
    "#pairs['name_ratio'] = ''\n",
    "idx = (pairs.applymap(type) == str).all(0)\n",
    "pairs_new = pairs[pairs.columns[idx]]\n",
    "\n",
    "for i in pairs.index:\n",
    "    if i % 100000 == 0:\n",
    "        print(i)\n",
    "    #print(pairs.loc[i,'city_1'],pairs.loc[i,'city_2'])\n",
    "    pairs.loc[i,'name_ratio'] = fuzz.ratio(pairs.loc[i,'name_1'],pairs.loc[i,'name_2'])\n",
    "    #pairs.loc[i,'city_ratio'] = fuzz.ratio(pairs.loc[i,'city_1'],pairs.loc[i,'city_2'])\n",
    "    #pairs.loc[i,'state_ratio'] = fuzz.ratio(pairs.loc[i,'state_1'],pairs.loc[i,'state_2'])\n",
    "    #pairs.loc[i,'zip_ratio'] = fuzz.ratio(pairs.loc[i,'zip_1'],pairs.loc[i,'zip_2'])\n",
    "    #pairs.loc[i,'country_ratio'] = fuzz.ratio(pairs.loc[i,'country_1'],pairs.loc[i,'country_2'])\n",
    "    #pairs.loc[i,'url_ratio'] = fuzz.ratio(pairs.loc[i,'url_1'],pairs.loc[i,'url_2'])\n",
    "    #pairs.loc[i,'categories_ratio'] = fuzz.ratio(pairs.loc[i,'categories_1'],pairs.loc[i,'categories_2'])\n",
    "    \n",
    "    #pairs.loc[i,'name_ratio_part'] = fuzz.partial_ratio(pairs.loc[i,'name_1'],pairs.loc[i,'name_2'])\n",
    "    #pairs.loc[i,'city_ratio_part'] = fuzz.partial_ratio(pairs.loc[i,'city_1'],pairs.loc[i,'city_2'])\n",
    "    #pairs.loc[i,'state_ratio_part'] = fuzz.partial_ratio(pairs.loc[i,'state_1'],pairs.loc[i,'state_2'])\n",
    "    #pairs.loc[i,'zip_ratio_part'] = fuzz.partial_ratio(pairs.loc[i,'zip_1'],pairs.loc[i,'zip_2'])\n",
    "    #pairs.loc[i,'country_ratio_part'] = fuzz.partial_ratio(pairs.loc[i,'country_1'],pairs.loc[i,'country_2'])\n",
    "    #pairs.loc[i,'url_ratio_part'] = fuzz.partial_ratio(pairs.loc[i,'url_1'],pairs.loc[i,'url_2'])\n",
    "    #pairs.loc[i,'categories_ratio_part'] = fuzz.partial_ratio(pairs.loc[i,'categories_1'],pairs.loc[i,'categories_2'])\n",
    "\n",
    "    \n",
    "print(pairs.head())\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "553197e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_1                      True\n",
       "name_1                    True\n",
       "latitude_1               False\n",
       "longitude_1              False\n",
       "address_1                 True\n",
       "city_1                    True\n",
       "state_1                   True\n",
       "zip_1                     True\n",
       "country_1                 True\n",
       "url_1                     True\n",
       "phone_1                   True\n",
       "categories_1              True\n",
       "id_2                      True\n",
       "name_2                    True\n",
       "latitude_2               False\n",
       "longitude_2              False\n",
       "address_2                 True\n",
       "city_2                    True\n",
       "state_2                   True\n",
       "zip_2                     True\n",
       "country_2                 True\n",
       "url_2                     True\n",
       "phone_2                   True\n",
       "categories_2              True\n",
       "match                    False\n",
       "name_ratio               False\n",
       "city_ratio               False\n",
       "state_ratio              False\n",
       "zip_ratio                False\n",
       "country_ratio            False\n",
       "url_ratio                False\n",
       "categories_ratio         False\n",
       "name_ratio_part          False\n",
       "city_ratio_part          False\n",
       "state_ratio_part         False\n",
       "zip_ratio_part           False\n",
       "country_ratio_part       False\n",
       "url_ratio_part           False\n",
       "categories_ratio_part    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pairs.applymap(type) == str).all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def fuzzy_match(df):\n",
    "    df = df.fillna('')\n",
    "    for i in df.index:\n",
    "        df.loc[i,'name_ratio'] = fuzz.ratio(df.loc[i,'name_1'],df.loc[i,'name_2'])\n",
    "        df.loc[i,'city_ratio'] = fuzz.ratio(df.loc[i,'city_1'],df.loc[i,'city_2'])\n",
    "        df.loc[i,'state_ratio'] = fuzz.ratio(df.loc[i,'state_1'],df.loc[i,'state_2'])\n",
    "        df.loc[i,'zip_ratio'] = fuzz.ratio(df.loc[i,'zip_1'],df.loc[i,'zip_2'])\n",
    "        df.loc[i,'country_ratio'] = fuzz.ratio(df.loc[i,'country_1'],df.loc[i,'country_2'])\n",
    "        df.loc[i,'url_ratio'] = fuzz.ratio(df.loc[i,'url_1'],df.loc[i,'url_2'])\n",
    "        df.loc[i,'categories_ratio'] = fuzz.ratio(df.loc[i,'categories_1'],df.loc[i,'categories_2'])\n",
    "    \n",
    "        df.loc[i,'name_ratio_part'] = fuzz.partial_ratio(df.loc[i,'name_1'],df.loc[i,'name_2'])\n",
    "        df.loc[i,'city_ratio_part'] = fuzz.partial_ratio(df.loc[i,'city_1'],df.loc[i,'city_2'])\n",
    "        df.loc[i,'state_ratio_part'] = fuzz.partial_ratio(df.loc[i,'state_1'],df.loc[i,'state_2'])\n",
    "        df.loc[i,'zip_ratio_part'] = fuzz.partial_ratio(df.loc[i,'zip_1'],df.loc[i,'zip_2'])\n",
    "        df.loc[i,'country_ratio_part'] = fuzz.partial_ratio(df.loc[i,'country_1'],df.loc[i,'country_2'])\n",
    "        df.loc[i,'url_ratio_part'] = fuzz.partial_ratio(df.loc[i,'url_1'],df.loc[i,'url_2'])\n",
    "        df.loc[i,'categories_ratio_part'] = fuzz.partial_ratio(df.loc[i,'categories_1'],df.loc[i,'categories_2'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193a494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f40d610",
   "metadata": {},
   "source": [
    "# Distance between points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "166a7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "\n",
    "def point_dist(df):\n",
    "    for i in df.index:\n",
    "        coord_1 = (df.loc[i,'latitude_1'],df.loc[i,'longitude_1'])\n",
    "        \n",
    "        coord_2 = (df.loc[i,'latitude_2'],df.loc[i,'longitude_2'])\n",
    "        \n",
    "        df['proximity'] = geopy.distance.geodesic(coord_1,coord_2).km\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee0f4d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                  name   latitude  longitude      address  \\\n",
      "0  E_000001272c6c5d  Café Stad Oudenaarde  50.859975   3.634196  Abdijstraat   \n",
      "\n",
      "         city            state   zip country  url phone categories  \\\n",
      "0  Nederename  Oost-Vlaanderen  9700      BE  NaN   NaN       Bars   \n",
      "\n",
      "  point_of_interest  \n",
      "0  P_677e840bb6fc7e  \n"
     ]
    }
   ],
   "source": [
    "print(train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c3379e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50.85997533509319, 3.6341963487748346)\n",
      "(-22.907225306597013, -43.17824390023254)\n"
     ]
    }
   ],
   "source": [
    "geo_df = train.head(2)\n",
    "coord_1 = (geo_df.loc[0,'latitude'],geo_df.loc[0,'longitude'])\n",
    "print(coord_1)\n",
    "coord_2 = (geo_df.loc[1,'latitude'],geo_df.loc[1,'longitude'])\n",
    "print(coord_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "527f92c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between point:  9370.64505095926\n"
     ]
    }
   ],
   "source": [
    "print('distance between point: ',geopy.distance.geodesic(coord_1,coord_2).km)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df19ac",
   "metadata": {},
   "source": [
    "# Check same language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9534b0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n",
      "ja\n",
      "it\n",
      "en\n",
      "pl\n",
      "\n",
      "[th:0.9999999994851496]\n",
      "[ja:0.9999998799866179]\n",
      "[so:0.9999985573962937]\n",
      "[en:0.7142849560981814, it:0.28571435583988425]\n",
      "[pl:0.8571394483837576, fi:0.14285787958897214]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langdetect import detect, DetectorFactory, detect_langs\n",
    "DetectorFactory.seed = 0\n",
    "# def detect_lang(text):\n",
    "#     return detect(text)\n",
    "\n",
    "# name_eda['name'].apply(detect_lang)\n",
    "\n",
    "print(detect('ร้านตัดผมการาเกด'))\n",
    "print(detect('ビックカメラ JR京都駅店'))\n",
    "print(detect('Hello Max'))\n",
    "print(detect('i am the automation'))\n",
    "print(detect(\"Otec matka syn.\"))\n",
    "print()\n",
    "\n",
    "\n",
    "print(detect_langs('ร้านตัดผมการาเกด'))\n",
    "print(detect_langs('ビックカメラ JR京都駅店'))\n",
    "print(detect_langs('hello max'))\n",
    "print(detect_langs('i am the automation'))\n",
    "print(detect_langs(\"Otec matka syn.\"))\n",
    "\n",
    "def same_lang(\n",
    "    df\n",
    "    ):\n",
    "    df['same_lang'] = 0\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    for i in df.index:\n",
    "        full_address_1 = (df.loc[i,'name_1'] + ' ' + df.loc[i,'address_1'] + ' ' + df.loc[i,'city_1'] + ' ' + df.loc[i,'state_1'] + ' ' + df.loc[i,'country_1'])\n",
    "        full_address_2 = (df.loc[i,'name_2'] + ' ' + df.loc[i,'address_2'] + ' ' + df.loc[i,'city_2'] + ' ' + df.loc[i,'state_2'] + ' ' + df.loc[i,'country_2'])\n",
    "        if (detect(full_address_1) == detect(full_address_2)):\n",
    "            df.loc[i,'same_lang'] = 1\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f0ae4cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode characters in position 0-5: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#better for shorter pieces of text - apparently langdetect needs long pieces\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(chardet\u001b[38;5;241m.\u001b[39mdetect(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mビックカメラ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp1251\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/encodings/cp1251.py:12\u001b[0m, in \u001b[0;36mCodec.encode\u001b[0;34m(self, input, errors)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;28minput\u001b[39m,errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoding_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode characters in position 0-5: character maps to <undefined>"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339a900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
